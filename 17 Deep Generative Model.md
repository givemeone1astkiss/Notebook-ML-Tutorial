# Deep Generative Model

## 1 Boltzmann Machines

玻尔兹曼机是一类（通常为二值变量的）概率无向图模型，其联合概率分布基于能量定义：
$$
P(x)=\frac{\exp(-E(x))}{Z}
$$
其中 $E(x)$ 是能量函数，$Z$ 是确保 $\sum_xP(x)=1$ 的配分函数，玻尔兹曼机的能量函数定义为：
$$
E(x)=-x^\top Ux-b^\top x
$$
其中 $U$ 是模型参数的“权重”矩阵，$b$ 是偏置向量。这个能量函数可以表示为因子图的视角，将 $b^\top x$ 理解为单节点因子，$x^\top U x$ 理解为双节点因子，我们就可以得到概率无向图因子分解的等价形式。

在上面这种定义方式中，我们没有对变量的类型进行区分，如果我们将所有单元分解为两个子集：可见单元 $v$ 和潜在单元 $h$，然后将能量函数写为：
$$
E(v,h)=-v^\top Rv-v^\top Wh-h^\top Sh-b^\top v-c^\top h
$$
潜在变量的作用类似于 MLP 中的隐藏层，这使得玻尔兹曼机变成了离散变量分布上概率质量函数的万能近似器。

玻尔兹曼机有一个有趣的性质，当基于最大似然的学习规则训练时，连接两个单元的特定权重的更新仅仅取决于这两个单元在不同分布下收集的统计信息：$P_{model}(v)$ 和 $\hat P_{data}(v)P_{model}(h\mid v)$，网络的其余部分参与塑造这些统计信息，但权重可以在完全不知道网络其余部分或这些统计信息如何产生的情况下更新，这其实是能量基模型或概率无向图模型的一般的联合概率的正负相分解性质的体现。

## 2 Restricted Boltzmann Machines (RBM)

RBM 在传统玻尔兹曼机的基础上进行了限制，其不不允许同种类型的单元之间有连接，因此是一个二分图模型。因此，其能量函数可以写成下面的形式：
$$
E(v,h)=-v^\top Wh-a^\top v-b^\top h
$$
其中 $Z$ 是被称为配分函数的归一化常数：
$$
Z=\sum_v\sum\exp\{-E(v,h)\}
$$
计算配分函数的朴素方法是难以处理的，难解的配分函数 $Z$ 意味着归一化的联合概率分布 $P(v)$，也难以评估。

我们在 RBM 的框架下说明玻尔兹曼机联合概率分布的正负相分解性质，我们将能量函数中的矩阵乘法展开为求和的形式：
$$
E(v,h)=-\sum_{i,j}v_i^\top W_{ij}h_j-\sum_ia_i^\top v_i-\sum_jb_j^\top h_j
$$
当我们以极大似然的框架进行学习时，我们的优化目标可以写作：
$$
\theta^*=\arg\max_{\theta}L(\theta)=\arg\max_\theta\sum_{v\in D}\log P(v),\theta=\{a_i,b_j,\theta_{ij}\}
$$
如果对参数 $w_{ij}$ 求偏导：
$$
\begin{aligned}
\frac{\partial L}{\partial w_{ij}}&=\sum_{v\in D}\frac{\partial}{\partial w_{ij}}\log P(v)\\
&=\sum_{v\in D}\frac{\partial}{\partial w_{ij}}\left(\log\sum_he^{-E(v,h)}-\log Z\right)\\
&=\sum_{v\in D}\left(-\frac{\sum_h\frac{\partial E}{\partial w_{ij}}e^{-E(v,h)}}{\sum_h e^{-E(v,h)}}+\frac{\sum_{v',h'}\frac{\partial E}{\partial w_{ij}}e^{-E(v',h')}}{Z}\right)\\
&=-\sum_{v\in D}\mathbb E_{h\sim P(h\mid v)}\left[\frac{\partial E}{\partial w_{ij}}\right]+\mathbb E_{v',h'\sim P(v,h)}\left[\frac{\partial E}{\partial w_{ij}}\right]\\
\end{aligned}
$$
再考察能量函数的偏导数：
$$
\frac{\partial L}{\partial w_{ij}}=-v_ih_i
$$
代入似然梯度表达式：
$$
\frac{\partial L}{\partial w_{ij}}=\sum_{v\in D}\mathbb E_{h\sim P(h\mid v)}[v_ih_j]-\mathbb E_{v',h'\sim P(v,h)}[v'_ih_j']
$$
这种性质来源于能量模型的一般性质，除此之外，RBM 作为二分图还有一类特殊性质，其条件分布  $P(h\mid v)$ 和 $P(v\mid h)$  是因子的，计算和采样是相对简单的：
$$
\begin{aligned}
P(h\mid v)&=\frac{P(h,v)}{P(v)}\\
&=\frac{1}{P(v)}\frac{1}{Z}\exp\{b^\top v+c^\top hv^\top Wh\}\\
&=\frac{1}{Z'}\exp\{c^\top h+v^\top Wh\}\\
&=\frac{1}{Z'}\exp\left\{\sum_{j=1}^{n_h}c_j^\top h_j+\sum_{n_h}^{j=1}v^\top W_{:,j}h_j\right\}\\
&=\frac{1}{Z'}\prod_{j=1}^{n_h}\exp\{c_j^\top h_j+v^\top W_{:,j}h_j\}\\
\end{aligned}
$$
因此，我们可以将条件概率分布写成单独元素上分布的乘积，如果我们考察单独元素的概率分布：
$$
\begin{aligned}
P(h_j=1\mid v)&=\frac{\widetilde P(h_j=1\mid v)}{\widetilde P(h_j=0\mid v)\widetilde P(h_j=1\mid v)}\\
&=\frac{\exp\{c_j+v^\top W_{:,j}\}}{\exp\{0\}+\exp\{c_j+v^\top W_{:,j}\}}\\
&=\sigma(c_j+v^\top W_{:,j})
\end{aligned}
$$
进而我们可以将条件概率分布完全表达为因子形式：
$$
P(h\mid v)=\prod_{j=1}^{n_h}\sigma((2h-1)\circ(c+W^\top v))_j\\
P(v\mid h)=\prod_{j=1}^{n_v}\sigma((2v-1)\circ(b+W^\top h))_i\\
$$
由于 RBM 允许高效计算 $\widetilde P(v)$ 的估计和微分，并且允许高效地进行 MCMC 采样（吉布斯块采样），我们可以使用 CD、SML、比率匹配等方式训练 RBM。

## 3 Deep Belief Networks

深度信念网络是最先引入深度架构训练的非卷积模型之一，是具有若干潜在变量层的生成模型，潜在变量通常是二值或实数，通常，每层的每个单元连接到每个相邻层的每个单元，顶部两层的连接是无向的，而其他层间连接是有向的，箭头指向最接近数据的层。

![DBN](./images/17.1.png)

具有 $l$ 个隐藏层的神经网络包含 $l$ 个权重矩阵：$W^{(1)},\dotsb,W^{(l)}$。同时也包含 $l+1$ 个偏置向量： $b^{(1)},\dotsb,b^{(l)}$，其中 $b^{(0)}$ 是可见层的偏置，DBN 的概率分布定义为：
$$
P(h^{(l)},h^{(l-1)})\propto \exp(b^{(l)\top} h^{(l)}+b^{(l-1)\top}h^{(l-1)}+h^{(l-1)}W^{(l)}h^{(l)})\\
P(h_i^{(k)}=1\mid h^{(k+1)})=\sigma(b_i^{(k)}+W_{:,i}^{(k+1)\top}h^{(k+1)}),\forall i,\forall k\in 1,\dotsb,l-2\\
P(v_i=1\mid h^{(1)})=\sigma(b_i^{(0)}+W_{:,i}^{(1)\top}h^{(1)}),\forall i
$$
或者可见单元为实数值时：
$$
v\sim \mathcal N(v;b^{(0)}+W^{(1)\top}h^{(1)},\beta^{-1})
$$
为了从 DBN 中采样，我们首先对顶部的两个隐藏层使用 Gibbs 采样，然后对其余部分使用单次原始采样。

由于每个有向层内部的相消解释效应，并且由于无向连接的两个隐藏层之间的相互作用，深度信念网络中的推断是难解的，评估或最大化对数似然的下界也是难以处理的，因为证据下界基于大小等于网络宽度的团的期望。

因此，评估或最大化 DBN 的似然需要同时处理来自前两个隐藏层的配分函数（无向图），和边缘化潜在变量时的推断问题。

DBN 的训练是逐层进行的，我们可以先使用 CD-k 或 SML 方法训练 RBM 以最大化  $\mathbb E_{v\sim p_{data}}\log p(v)$，RBM的参数定义了 DBN 第一层的参数，然后，第二个 RBM 的训练基于最大化：
$$
\mathbb E_{v\sim p_{data}}\mathbb E_{h^{(1)}\sim p^{(1)}(h^{(1)}\mid v)}\log p^{(2)}(h^{(1)})
$$
因此，第二个 RBM 被训练为模拟由第一个 RBM 隐藏单元采样定义的概率分布，而第一个 RBM 由数据驱动，这个过程可以无限重复。

再经过贪心逐层训练之后，DBN 通常能够取得较好的效果，但是使用醒眠算法对其进行微调是可能的。

训练好的 DBN 可以直接而做为生成模型进行采样，但是 DBN 的另一个用处是其改进分类模型的能力，我们可以从 DBN 中获取权重，并使用它们定义 MLP：
$$
h^{(1)}=\sigma(b^{(1)}+v^\top W^{(1)})\\
h^{(l)}=\sigma(b_i^{(i)}+h^{(l-1)\top}W^{(l)}),\forall l\in 2,\dotsb,m
$$
利用 DBN 的生成训练后获得的权重和偏置初始化该 MLP 之后，我们可以训练该 MLP 来执行分类任务。

## 4 Deep Boltzmann Machine (DBM)

深度玻尔兹曼机是另一种深度生成模型，其特点是完全无向，与 RBM 一样，DBM 通常仅包含二值节点，但是很容易就可以拓展至实值节点。

![DBM](./images/17.2.png)

DBM 是基于能量的模型，这意味着模型变量的联合概率分布由能量函数定义，例如对于一个包含一个可见层 $v$ 和三个隐藏层的 $h^{(1)}$、$h^{(2)}$、$h^{(3)}$ 的情况，联合概率分布由下式给出（省略偏置）：
$$
P(v,h^{(1)},h^{(2)},h^{(3)})=\frac{1}{Z(\theta)}\exp(-E(v,h^{(1)},h^{(2)},h^{(3)};\theta))\\
E(v,h^{(1)},h^{(2)},h^{(3)};\theta)=-v^\top W^{(1)}h^{(1)}-h^{(1)\top}W^{(2)}h^{(2)}-h^{(2)\top}W^{(3)}h^{(3)}
$$
与 RBM 相比， DBM 的能量函数的定义中还增加了对隐藏层之间连接的表示。

![DBM](./images/17.3.png)

尽管引入了层次化的结构，但是 DBM 还是可以像 RBM 一样改写为二分图的形式，其中奇数层位于一侧，偶数层位于另一侧，当我们条件于奇数层中的变量时，偶数层中的变量变得条件独立，当我们 条件于偶数层中的变量时，奇数层中的变量变得条件独立。

类似于 RBM，对于具有两个隐藏层的 DBM，我们可以这样表示激活概率（省略偏置）：
$$
P(v_1\mid h^{(1)})=\sigma(W^{(1)}_{i,:}h^{(1)})\\
P(h^{(1)}_i=1\mid v,h^{(2)})=\sigma(v^\top W^{(1)}_{:,i}+W_{i,:}^{(2)}h^{(2)})\\
P(h_k^{(2)}=1\mid h^{(k)})=\sigma(h^{(1)\top}W^{(2)}_{:,k})
$$
由于 DBM 的二分图结构，我们能够使用 Gibbs 块采样从中高效地获取样本，例如我们可以将所有单元分为两个块，其中一块包含所有的偶数层，另一块包含所有的奇数层。

与 DBN 相比，DBM 的后验分布 $P(h\mid v)$ 更简单，这使得更丰富的后验近似是可能的，DBM 的一个不理想的性质是从中采样是相对困难的。DBN 的采样过程仅涉及再前两层使用 MCMC 采样，其后只需要对剩余层使用高效的原始采样，但是要从 DBM 中生成样本，必须在所有层中使用 MCMC，并且模型的每一层都参与每个马氏链转移。

以带有两个隐藏层的 DBM 为例，相邻层条件下的单层条件概率分布是因子的（$P(v\mid h^{(1)}),P(h^{(1)}\mid h^{(2)},v),P(h^{(2)}\mid h^{(1)})$），而给定观测层在所有隐藏层上的条件概率分布不是因子的（$P(h^{(1)},h^{(2)}\mid v)$），这是由两个隐藏层之间的连接权重 $W^{(2)}$ 导致的。对于这种非因子的形式不良的分布，我们可以使用均匀场推断的方法进行简化。

所谓均匀场推断，指的是变分推断的一种特殊情况，即我们采用的变分分解的因子均为单变量的条件概率的情况，或者更具体地：
$$
Q(h^{(1)},h^{(2)}\mid v)=\prod_j Q(h^{(1)}_j\mid v)\prod_k Q(h^{(2)}_k\mid v)
$$
与一般的变分推断一致，均匀场推断的目标是最小化：
$$
KL(Q\|P)=\sum_hQ(h^{(1)},h^{(2)}\mid v)\log \left(\frac{Q(h^{(1)},h^{(2)}\mid v)}{P(h^{(1)},h^{(2)}\mid v)}\right)
$$
在二值 DBM 中，我么们将 $Q$ 作为伯努利分布的乘积进行参数化对于每个 $j$，我们定义：$\hat h_j^{(1)}=Q(h^{(1)}_j=1\mid v)$，同样的对于每个 $k$，$\hat h_k^{(2)}=Q(h^{(2)}_k=1\mid v)$，因此近似后验的形式可以写作：
$$
Q(h^{(1)},h^{(2)}\mid v)=\prod_j (\hat h_j^{(1)})^{h^{(1)}_j}(1-\hat h_j^{(1)})^{(1-h^{(1)}_j)}\times\prod_k (\hat h_k^{(1)})^{h^{(1)}_k}(1-\hat h_k^{(1)})^{(1-h^{(1)}_k)}
$$
使用变分推断的一般更新方程，我们可以对近似后验的因子进行轮流更新：
$$
h_j^{(1)}=\sigma\left(\sum_i v_iW_{i,j}^{(1)}+\sum_{k'}W_{j,k'}^{(2)}\hat h_{k'}^{(2)}\right),\forall j\\
h_k^{(2)}=\sigma\left(\sum_{j'}W_{j',k}^{(2)}\hat h_{j'}^{(2)}\right),\forall k
$$
由均匀场推断得出的变分后验的下界是：
$$
\mathcal L(Q,\theta)=\sum_i\sum_{j'}v_iW_{i,j'}^{(1)}\hat h^{(1)}_{j'}+\sum_{j'}\sum_{k'}h_{j'}^{(1)}W_{j',k'}^{(2)}\hat h^{(2)}_{k'}-\log Z(\theta)+\mathcal H(Q)
$$
变分下界的表达式中仍然包含配分函数，而计算 DBM 的配分函数的困难与 RBM 一致，因此评估 DAM 的概率质量函数需要使用近似方法，在 DBM 中通常使用 SML 方法，那些对非归一化的概率有直接依赖的方法并不适用于 DBM。

![SML](./images/17.4.png)

通常随机初始化之后使用极大似然方法训练 DBM 会导致失败，一般的解决方式是使用贪心逐层训练。在训练过程中，第一层被训练为对输入数据进行建模，每个后续 RBM 被训练为对来自前一 RBM 后验分布的样本进行建模，在以这种方式训练了所有 RBM 之后，它们可以被组合为 DBM，然后我们使用 SML 方法对 DBM 进行训练。

DBM 的贪心逐层预训练与 DBN 不同，每个单独的 RBM 的参数可以直接复制到相应的 DBN，但是在包含到 DBM 中必须进行修改。因为 RBM 的中间层仅使用自底向上的输入进行训练，但在栈组合形成 DBM 之后，该层将同时具有自底向上和自顶向下的输入。因此，在插入 DBM 之前，所有中间层的 RBM 的权重应该除以二，同时必须使用可见单元的两个“副本”训练底部RBM，两个副本的权重被约束为相等，这意味着向上传播的过程中权重可以有效地加倍。类似地，顶部 RBM 应该使用最顶层的两个副本来训练。

![DBM](./images/17.5.png)

经典 DBM 需要无监督预训练，并且为了更好地分类，需要在它们提取的隐藏特征之上使用独立的基于 MLP 的分类器，使用这种预训练方式有若干弊端：

- 不能在训练第一个 RBM 时评估完整 DBM 的属性，所以在训练时难以跟踪其性能
- 实现需要很多不同的模块
- 玻尔兹曼机顶部的 MLP 失去了玻尔兹曼机概率模型的许多优点

有两个方法可以解决 DBM 的联合训练问题：

- **中心化深度玻尔兹曼机：**通过重参数化模型使其在开始学习的过程时代价函数的 Hessian 具有更好的条件数，使得模型无需经过贪心逐层预训练就可以使用 SML 进行训练。但是作为分类器仍不能与 MLP 竞争。
- **多预测深度玻尔兹曼机：**该模型的训练允许反向传播算法，以避免使用 MCMC 估计梯度的问题，会带来更好的分类性能和良好的推断缺失输入的能力。

对于一般的玻尔兹曼机，能量函数表示为：
$$
E(x)=-x^\top Ux-b^\top x
$$
通过在权重矩阵 $U$ 中使用不同的稀疏模式，我们可以实现不同架构的玻尔兹曼机。中心化玻尔兹曼机引入一个向量 $\mu$，并从所有状态中减去：
$$
E'(x,U,b)=-(x-\mu)^\top U(x-\mu)-(x-\mu)^\top b
$$
通常在 $\mu$ 开始训练时固定为一个超参数，当模型初始化时，通常选择为 $x-\mu\simeq0$，这种重参数化不改变模型可表示的概率分布的集合，但是它确实能够导致更好条件数的 Hessian 矩阵，并且等价于另一个玻尔兹曼机学习技术——增强梯度。

而多预测深度玻尔兹曼机（MP-DBM）将均匀场方程定义为一系列用于近似求解每个可能推断问题的循环网络，模型被训练为使每个循环网络获得对应推断问题的准确答案，而不是随机最大化似然。训练过程包括随机采样一个训练样本，随机采样推断网络的输入子集，然后训练推断网络来预测剩余单元的值。

这种用于近似推断，通过计算图进行反向传播的一般原理已经应用于其他模型，在这些模型和 MP-DBM 中，最终损失不是似然的下界，而是通常基于近似推断网络对缺失值施加的近似条件分布。

通过推断图的反向传播有两个优点：

- 通过近似推断，以模型真正被使用的方式训练模型，因此在 MP-DBM  中，进行如填充缺失的输入或执行分类（尽管存在缺失的输入）的近似推断比在原始 DBM 中更准确。原始 DBM 的分类是基于 DBM 提取的特征训练独立的分类器，而不是通过 DBM 中的推断来计算关于类标签的分布，而 MP-DBM 中使用均匀场推断作为分类器。
- 另一个优点是能够计算损失函数的准确梯度，这好于 SML 使用的近似梯度，因此在训练过程中的偏差及方差较小。

![MP-DBM](./images/17.6.png)

## 5 Boltzmann Machines for Real-Valued Data

### 5.1 Gaussian-Bernoulli RBM

Gaussian-Bernoulli RBM 具有二值隐藏单元和实值可见单元，其中可见单元上的分布是高斯分布（均值为隐藏单元的函数）。

Gaussian-Bernoulli RBM 的参数化形式很多，我们可以选择协方差矩阵或精度矩阵来参数化高斯分布，例如使用精度矩阵的形式：
$$
p(v\mid h)=\mathcal N(v\mid Wh,\beta^{-1})
$$
通过扩展未归一化的对数条件分布可以找到需要添加到能量分布中的项：
$$
\log \mathcal N(v\mid Wh,\beta^{-1})=-\frac12 (v-Wh)^\top\beta(v-Wh)+f(\beta)
$$
此处的 $f$ 的作用是归一化分布。

如果我们在能量函数中包含涉及 $v$ 的所有项，并且不添加其他涉及 $v$ 的项，那么我们的能量函数就能够表示想要的条件分布 $p(v\mid h)$ 。

 注意到高斯分布的对数形式中含有一项：
$$
\frac12 h^\top W^\top\beta Wh
$$
这一项不能全部包含于能量函数中，因为其中 $h_ih_j$ 的项表示了隐藏节点之间的连接，如果我们简单地将这些项包含入能量函数中，我们会得到一个线性因子模型而非 RBM ，因此我们简单地省略 $h_ih_j$ 的交叉项，省略这些项不会改变 $p(v\mid h)$ 的形式（因为 $h$ 是作为条件给出）。然而另一个因子是否应该保留是值得考虑的，假设精度矩阵为对角矩阵，那么对于每个隐藏单元 $h_j$ ，包含一项：
$$
\frac12 h_i\sum_j\beta_jW_{j,i}^2
$$
如果我们在能量函数中包含此项，则当该单元的权重较大且以高精度连接到可见单元时，偏置 $h_j$ 被自然关闭。是否包含该偏置项不会影响模型可以表示的分布族，但是它能够影响模型学习动态，包括该项可以帮助隐藏单元保持合理激活。

因此，在 Gaussian-Bernoulli RBM 中定义能量函数的一种方式是：
$$
E(v,h)=\frac12 v^\top(\beta\circ v)-(v\circ\beta)^\top Wh-b^\top h
$$
 Gaussian-Bernoulli RBM 形式上的变化的一个主要来源是如何处理精度矩阵，它可以被固定为常数或学习出来，可以是标量乘以单位矩阵或者对角矩阵，在此情况下，由于一些操作需要对矩阵求逆，我们通常不允许非对角的精度矩阵，因为一个对角矩阵通常可以非常容易地求逆。

### 5.2 Undirected Models of Conditional Covariance

 Gaussian-Bernoulli RBM 并不能捕捉实值中的条件协方差信息，而这类信息对于很多类型的实值数据是非常重要的。为了解决这个问题，有三类实值玻尔兹曼机模型：

- **均值和协方差 RBM（mean and covariance RBM, mcRBM）**
- **学生 t 分布均值乘积模型（mean product of Student t-distribution, mPoT）**
- **尖峰和平板 RBM（spike and slab RBM, ssRBM）**

mcRBM 使用隐藏单元独立地编码所有可观察单元的条件均值和协方差。mcRBM 分为两组单元：均值单元和协方差单元，建模条件均值的单元式简单的 Gaussian-Bernoulli RBM，另一半式协方差 RBM。

具体来说，在二值均值单元 $h^{(m)}$ 和二值协方差单元 $h^{(n)}$ 的情况下，mcRBM 模型被定义为两个能量函数的组合：
$$
E_{mc}(x,h^{(m)},h^{(n)})=E_m(x,h^{(m)})+E_c(x,h^{(n)})
$$
其中 $E_m$ 表示标准的 Gaussian-Bernoulli RBM 能量函数：
$$
E_{m}(x,h^{(m)})=\frac12 x^\top x-\sum_j x^\top W_{:,j}h_j^{(m)}-\sum_j b_j^{(m)}h_j^{(m)}
$$
而 $E_c$ 是 cRBM 建模条件协方差信息的能量函数：
$$
E_c(x,h^{(c)})=\frac12 \sum_j h_j^{(c)}(x^\top r^{(j)})^2-\sum_jb_j^{(c)}h_j^{(c)}
$$
参数 $r^{(j)}$ 与 $h_j^{(c)}$ 关联的协方差权重向量对应，$b^{(c)}$ 是一个协方差偏置向量。组合后的能量函数定义联合分布：
$$
P_{mc}(x,h^{(m)},h^{(c)})=\frac1Z \exp\{-E_{mc}(h^{(m)},h^{(c)})\}
$$
以及条件分布（多元高斯分布）：
$$
P_{mc}(x\mid h^{(m)},h^{(c)})=\mathcal N\left(x\mid C_{x\mid h}^{mc}\left(\sum_j W_{:,j}h_h^{(m)}\right),C_{x\mid h}^{mc}\right)
$$
注意协方差矩阵 $C_{x\mid h}^{mc}=\left(\sum_j h_j^{(c)}r^{(j)}r^{(j)\top}+I\right)^{-1}$ 是非对角的，且 $W$ 是与建模条件均值的 Gaussian-Bernoulli RBM 相关的权重矩阵。由于非对角的协方差结构，难以通过对比散度或持续性对比散度来训练 mcRBM ，因为从 $P_{mc}(x\mid h^{(m)},h^{(n)})$ 中抽样需要在学习的每个迭代计算 $(C^{mc})^{-1}$，这对于更大的观察数据可能是不切实际的计算负担。一些可行的办法是使用 mcRBM 自由能上的哈密顿蒙特卡洛直接从边缘分布 $P(x)$ 中采样。

学生 t 分布均值乘积模型以类似 mcRBM 扩展 cRBM 的方式扩展 PoT 模型。与 mcRBM 一样，观察值上 的 PoT 条件分布是多元高斯分布（非对角协方差），但是不同的是，隐藏变量的互补条件分布是由条件独立的 Gamma 分布给出的，Gamma 分布 $\mathcal G(k,\theta)$ 是关于正实数且均值为 $k\theta$ 的概率分布：
$$
E_{mPoT}(x,h^{(m)},h^{(n)})=E_m(x,h^{(m)})+\sum_j\left(h_j^{(c)}(1+\frac12 (r^{(j)\top}x)^2)+(1-\gamma_j)\log h_j^{(c)}\right)
$$
其中 $r^{(j)}$ 是与单元 $h_j^{(c)}$ 相关联的协方差权重向量，$E_m$ 的形式与 mcRBM 相同。

正如 mcRBM 一样，mPoT 模型能量函数指定一个多元高斯分布，其中关于 $x$ 的条件分布具有非对角的协方差。mPoT 模型中的学习由于无法从非对角高斯分布采样而变得复杂。

ssRBM 与 mcRBM 相比无需对矩阵求逆或使用哈密顿蒙特卡洛的方式采样，与前两个模型一样，ssRBM 的二值隐藏单元通过使用辅助实值。

ssRBM 有两类隐藏单元，二值尖峰单元 $h$ 和实值平板单元 $s$，条件于隐藏单元的可见单元均值由 $(h\circ s)W^\top$ 给出。换句话说，每列 $W_{:,i}$ 定义当 $h_i=1$ 时可出现在输入中的分量。相应的尖峰变量 $h_i$ 确定该分量是否存在，如果存在的话，平板分量 $s_i$ 确定分量的强度。当尖峰变量激活时，相应的平板变量将沿着 $W_{:,i}$ 定义的轴的输入方向增加方差，这允许我们对输入的协方差建模，幸运的是，使用 Gibbs 采样的对比散度和持续性对比散度方法仍然适用，此处无需任何矩阵求逆。

形式上，ssRBM 的能量函数表示为：
$$
E_{ss}(x,s,h)=-\sum_i x^\top W_{:,i}s_ih_i+\frac12x^\top\left(\Lambda +\sum_i\Phi_ih_i\right)x+\frac12 \sum_i\alpha_is_i^2-\sum_i\alpha_i\mu_is_ih_i-\sum_ib_ih_i+\sum_i\alpha_i\mu_i^2h_i
$$
其中  $b_i$ 是尖峰 $h_j$ 的偏置，$\Lambda$ 是观测值 $x$ 上的对角精度矩阵。参数 $\alpha>0$ 是实值平板向量  $s_i$ 的标量精度函数，参数 $\Phi_i$ 是定义在 $x$ 上的 $h$ 调制二次惩罚的非负对角矩阵。每个 $\mu_i$ 是平板变量 $s_i$ 的均值参数。

利用能量函数定义的联合概率分布，能相对容易地导出 ssRBM 条件分布。例如，通过边缘化平板变量 $s$，给定二值尖峰变量 $h$，关于观察量的条件分布由下式给出：
$$
P_{ss}(x\mid h)=\frac1{P(h)}\frac1Z\int\exp\{-E(x,s,h)\}\mathrm ds=\mathcal N\left(x\mid C_{x\mid h}^{ss}\sum_iW_{:,i}\mu_ih_i,C^{ss}_{x\mid h}\right)
$$
其中 $C_{x\mid h}^{ss}=(\Lambda +\sum_i\Phi_ih_i-\sum_i\alpha_i^{-1}h_iW_{:,i}W_{:,i}^\top)^{-1}$。最后的等式只有在协方差矩阵 $C_{x\mid h}^{ss}$ 正定的售后才成立。

由尖峰变量门控意味着 $h\circ s$ 上的真实边缘分布是稀疏的，不同于稀疏编码，其中来自模型的样本在编码中”几乎从不“包含零，并且需要 MAP 推断加强稀疏性。

ssRBM 以明显不同的方式参数化观察量的条件协方差。mmRBM 和 mPoT 都通过 $(\sum_jh_j^{(c)}r^{(j)}r^{(j)\top}+I)^{-1}$ 建模观察量的协方差结构，使用 $h_j>0$ 的隐藏单元的激活来对方向 $r^{(j)}$ 的条件协方差施加约束。相反，ssRBM 使用隐藏尖峰激活 $h_i=1$ 来指定观察结果的条件协方差，以沿着由相应权重向量指定的方向捏合精度矩阵。在过完备（指在表示系统中使用的基函数（或特征）数量超过原始信号的维度，从而提供更灵活、更稀疏的数据表示方式）的设定下，ssRBM参数化的稀疏激活仅允许在稀疏激活 $h_i$ 的所选方向上有显著方差（高于由 $\Lambda^{-1}$ 给出的近似方差），在 mcRBM 或 mPoT 模型中，过完备的表示意味着捕获观察空间中特定方向上的变化需要在该方向上的正交投影下去除潜在的所有约束，这表明这些模型不太适合过完备设定。

ssRBM 的主要缺点是参数的一些设置会对应于非正定的协方差矩阵。 这种协方差矩阵会在离均值更远的值上放置更大的未归一化概率，导致所有可能结果上的积分发散。

## 6 Back-Propagation through Random Operations

### 6.1 Reparametrization Trick

在生成式模型中我们通常希望实现 $x$ 的随机变换，这样做的一个直接方法是使用额外的输入 $z$ 来增强神经网络，从而确保网络在内部仍可以继续执行确定性计算。例如，我们考虑从 $\mathcal N(\mu,\sigma^2)$ 中采样 $y$ 的操作，我们可以将采样过程重写为：
$$
y = \mu+\sigma z，z\sim \mathcal N(\mu,\sigma^2)
$$
现在我们将其视为具有输入 $z$ 的确定性操作，可以关于 $\mu$ 和 $\sigma$ 求梯度，而额外输入是一个随机变量，其分布不是需要计算梯度的变量的函数。

这种原理能够广泛地使用，我们可以将任何形为 $p(y\mid \theta)$ 或 $p(y\mid x,\theta)$ 的概率分布表示为 $p(y\mid \omega)$ 其中 $\omega$ 是同时包含参数 $\theta$ 和输入 $x$ 的变量，从给定分布 $y\sim p(y\mid \omega)$ 中采样的过程可以重写为确定的 $y=f(z;\omega)$，只要 $f$ 是处处可微的，我们就可以使用传统工具计算 $y$ 相对于 $\omega$ 的导数。

这种技巧被称为重参数化技巧或随机反向传播。对于 $f$ 并非连续可微的情况，例如 $y$ 为离散变量的情况，我们可以使用强化学习算法（如 REINFORCE 算法）对 $\omega$ 上的梯度进行估计。

### 6.2 Back-Propagation through Random Operations

当 $y$ 为离散变量时，重参数化技巧不再适用，此时 $f$ 表示一个阶跃函数，其导数阶跃边界是未定义的，且在阶跃边界之间的区域几乎处处为零，因此任何代价函数的 $J(y)$ 的导数无法给出参数更新的任何信息。

REINFORCE 算法的思想是即使 $J(f(z;\omega))$ 是无导数的阶跃函数，期望代价 $\mathbb E_{z\sim p(z)}J(f(z;w))$ 通常是服从梯度下降的光滑函数。虽然当 $y$ 是高维变量时，该期望通常是难解的，但是我们可以用蒙特卡洛方法实现无偏估计。通过简单地计算微分期望成本，我们可以导出 REINFORCE 算法的最简单版本：
$$
\mathbb E_z[J(y)]=\sum_yJ(y)p(y)\\
\frac{\partial \mathbb E[J(y)]}{\partial \omega}=\sum_yJ(y)\frac{\partial p(y)}{\partial \omega}=\sum_yJ(y)p(y)\frac{\partial \log p(y)}{\partial \omega}\simeq \frac1m \sum_{y^{(i)}\sim p(y),i=1}^mJ(y^{(i)})\frac{\partial \log p(y^{(i)})}{\partial \omega}
$$
简单 REINFORCE 算法估计的一个问题是其具有非常高的方差，需要采用 $y$ 的许多样本才能够获得对梯度的良好估计，或者等价地，仅绘制一个样本，SGD 将会收敛地非常缓慢且需要较高的学习率。

方差减小方法可以减少该估计的方差。在 REINFORCE 方法下提出的方差减小方法涉及计算用于偏移 $J(y)$ 的基线，不依赖 $y$  任何偏移 $b(\omega)$ 都不会改变估计梯度的期望，因为：
$$
\mathbb E_{p(y)}\left[\frac{\partial \log p(y)}{\partial \omega}\right]=\sum_yp(y)\frac{\partial \log p(y)}{\partial \omega}=\sum_y \frac{\partial p(y)}{\partial \omega}=\frac{\partial}{\partial\omega}\sum_yp(y)=\frac{\partial}{\partial\omega}1=0
$$
因此：
$$
\mathbb E_{p(y)}\left[(J(y)-b(\omega))\frac{\partial \log p(y)}{\partial \omega}\right]=\mathbb E_{p(y)}\left[J(y)\frac{\partial \log p(y)}{\partial \omega}\right]-b(\omega)\mathbb E_{p(y)}\left[\frac{\partial \log p(y)}{\partial \omega}\right]=\mathbb E_{p(y)}\left[J(y)\frac{\partial \log p(y)}{\partial \omega}\right]
$$
此外，我们可以通过计算 $(J(y)-b(\omega))\frac{\partial \log p(y)}{\partial\omega}$ 关于 $p(y)$ 的方差，并关于 $b(\omega)$ 最小化获得最优 $b(\omega)$ 。我们发现这个最佳基线 $b^*(\omega)_i$ 对于向量 $\omega$ 的每个元素 $\omega_i$ 是不同的：
$$
b^*(\omega)_i=\frac{\mathbb E_{p(y)}\left[J(y)\frac{\partial \log p(y)^2}{\partial \omega_i}\right]}{\mathbb E_{p(y)}\left[\frac{\partial \log p(y)^2}{\partial \omega_i}\right]}
$$
相对 $\omega_i$ 的估计则变为：
$$
(J(y)-b(\omega)_i)\frac{\partial \log p(y)}{\partial \omega_i}
$$
其中 $b(\omega)_i$ 是对 $b^*(\omega)_i$ 的估计，获得估计 $b$ 通常需要将额外的输出添加到神经网络，并训练新输出对 $\omega$ 的每个元素估计 $\mathbb E_{p(y)}[J(y)\frac{\partial \log p(y)^2}{\partial \omega_i}]$ 和 $\mathbb E_{p(y)}[\frac{\partial \log p(y)^2}{\partial \omega_i}]$ 。这些额外的输出可以用均方根误差作为目标训练，对于给定的 $\omega$ ，从 $p(y)$ 采样 $y$ 时，分别用 $J(y)\frac{\partial \log p(y)^2}{\partial \omega_i}$ 和 $\frac{\partial \log p(y)^2}{\partial \omega_i}$ 作为目标，然后可以从估计式中恢复  $b$ 。

## 7 Directed Generative Nets

### 7.1 Sigmoid Belief Network

sigmoid 信念网络是一类具有特定条件概率分布的有向图模型的简单形式。一般来说，我们可以将 sigmoid 信念网络视为具有二值向量的状态 $s$，其中状态的每个元素受其祖先影响：
$$
p(s_i)=\sigma\left(\sum_{j<i}W_{j,i}s_j+b_i\right)
$$
sigmoid 信念网络最常见的结构是被分为许多层的结构，其中原始采样通过一系列多个隐藏层进行，然后最终生成可见层。这种结构与深度信念网络非常相似，但它们在采样过程开始时的单元彼此独立，而不是从受限玻尔兹曼机采样。

对于 sigmoid 信念网络来说，生成可见单元的样本是高效的，但是其他大多数操作不是很高效。对隐藏单元的推断是难解的，因为变分下界涉及对包含整个层的团求期望，均匀场推断也是难解的。

一种特殊的 sigmoid 信念网络是没有潜在变量的情况，这种情况下的学习是高效的，因为没有必要将潜在变量边缘化到似然之外。

### 7.2 Differentiable Generator Networks

可微生成器模型使用可微函数  $g(z;\theta^{(g)})$ 将潜在变量变换为样本 $x$ 或者样本 $x$ 上的分布，可微函数通常以神经网络表示，这类模型包括将生成器网络与推断网络配对的变分自编码器，将生成器网络与判别器网络配对的生成对抗式网络以及孤立地训练生成器网络的技术。

生成器网络本质上只是生成样本过程的参数化，例如，从具有均值 $\mu$ 和协方差 $\Sigma$ 的正态分布绘制样本的标准过程是将来自零均值和单位协方差矩阵的正态分布的样本 $z$ 馈送至一个单仿射层的生成器网络中：
$$
x=g(z)=\mu+Lz
$$
其中 $L$ 由 $\Sigma$ 的 Cholesky 分解给出。

逆变换采样同样依托这个原理，但是要求目标分布的累积分布函数的反函数是可解的。我们从均匀分布 $U(0,1)$ 中采样 $z$，然后 $g(z)$ 由累积分布函数 $F(x)=\int_{-\infty}^x p(v)\mathrm dv$ 的反函数给出。

为了从更复杂的分布中采样，可以使用前馈神经网络表示非线性函数 $g$ 的参数族，并使用训练数据来推断参数以选择所期望的参数。

对于可逆、可微的 $g$，我们可以由变量替换定理得到：
$$
p_z(z)=p_x(g(z))\left|\mathrm{det}(\frac{\partial g}{\partial z})\right|
$$
这隐含对 $x$ 施加分布：p_
$$
p_x(x)=\frac{p_x(g^{-1}(x))}{|\mathrm{det}(\frac{\partial g}{\partial z})|}
$$
取决于 $g$ 的选择，这个公式可能很难评估，因此我们常常需要使用间接学习的方法，而不是直接极大似然。

在另一些情况下，我们使用 $g$ 来定义 $x$ 上的条件分布，而不是使用 $g$ 直接提供 $x$ 的样本。这种情况下我们对 $z$ 进行边缘化而得到 $x$ 上的边缘分布：
$$
p(x)=\int_zp(x\mid z)p(z)\mathrm dz=\mathbb E_{z\sim p(z)}p(x\mid z)
$$
这两种表示方法各有优劣，当生成器网络定义条件分布时，它不但能生成连续数据，还能生成离散的数据，而当生成器网络直接提供采样时，它只能产生连续的数据，因为离散数据的累积概率密度函数并不满足可微的要求，如果我们在前向传播过程中进行离散化，那么网络不再能由反向传播进行训练，直接采样的优点是我们不再被迫使用条件分布。

### 7.3 VAE

VAE 是使用可学习的变分推断的有向图模型，可以使用纯粹的梯度下降的方式训练。

为了从模型产生样本，VAE 首先从编码分布 $p_{model}(z)$ 中采样 $z$，然后使样本通过可微生成器网络 $g(z)$，最后从分布 $p_{model}(x;g(z))=p_{model}(x\mid z)$ 中采样 $x$，然而在训练期间，近似推断网络（或编码器）$q(z\mid x)$ 用于获得 $z$，而 $p_{model}(x\mid z)$ 被视为解码器网络。

变分自编码器的关键思想是可以通过最大化与数据点相关联的变分下界 $\mathcal L(q)$ 来训练：
$$
\begin{aligned}
\mathcal L(q)&=\mathbb E_{z\sim q(z\mid x)}\log p_{model}(z,x)+\mathcal H(q(z\mid x))\\
&=\mathbb E_{z\sim q(z\mid x)}\log p_{model}(x\mid z)-D_{KL}(q(z\mid x)\|p_{model}(z))\\
&\leq \log p_{model}(x)
\end{aligned}
$$
变分推断和学习的传统方法是通过优化算法推断 $q$，通常是通过迭代不动点方程。这些方式是缓慢的，并且需要以闭解形式计算 $\mathbb E_{z\sim q}\log p_{model}(z,x)$。变分自编码器背后的主要思想是训练产生 $q$ 参数的参数编码器。只要 $z$ 是连续变量，我们就可以从 $q(z\mid x)=q(z;f(x;\theta))$ 中采样 $z$ 的样本反向传播，以获得相对 $\theta$ 的梯度，学习则仅包括相对于编码器和解码器的参数最大化 $\mathcal L$，其中的所有期望都可以通过蒙特卡洛采样近似。

变分自编码器的主要缺点是从图像上训练的变分自编码器中采样的样本往往会有些模糊，这可能是最大似然的固有效应，因为我们需要最小化 $D_{KL}(p_{data}\|p_{model})$，这意味着模型将为训练集中出现的点分配高的概率，但也可能为其他点分配高的概率，还有其他原因可以导致模糊图像，例如实际使用的变分自编码器通常在 $p_{model}(x\mid g(z))$ 使用高斯分布，最大化这种分布似然性的下界与训练具有均方误差的传统自编码器类似，这意味着它会倾向于忽略由少量像素表示的特征或亮度变化微小的像素。

另一个问题是 VAE倾向于仅使用 $z$ 维度中的小子集，就像编码器不能够将具有足够局部方向的输入空间变换到边缘分布与分解前匹配的空间。

VAE 的一个关键优势是可以扩展到大范围的模型架构，可以与广泛的微分算子族一起良好工作，与之相比 Boltzmann machine 需要非常仔细地设计来保持易解性。

变分自编码器的一个非常好的特性是，同时训练参数编码器与生成器网络的组合迫使模型学习一个编码器可以捕获的可预测的坐标系。这使得它成为一个优秀的流形学习算法。

### 7.4 GAN

生成对抗式网络由生成器网络和判别器网络组成，前者直接产生样本 $z=g(z;\theta^{(g)})$，后者试图区分从训练数据中抽取的样本和从生成器抽取的样本。判别器发出由 $d(x;\theta^{(d)})$ 给出的概率值，指示 $x$ 是真实训练样本的概率。

生成对抗网络可以被简单地描述为零和游戏，其中函数  $v_{\phi,\psi}$ 确定判别器的收益，生成器接受 $-v(\phi,\psi)$ 作为自己的收益，他们各自尝试最大化自己的收益：
$$
g^*=\arg\min_\phi\max_\psi v_{\phi,\psi}
$$
v 的默认选择是：
$$
v_{\phi,\psi}=\mathbb E_{x\sim p_{data}}\log d(x)+\mathbb E_{x\sim p_{model}}\log (1-d(x))
$$
优化目标驱使判别器试图学习将样品正确地分类为真的或者伪造的，同时，生成器试图欺骗分类器以让其相信样本是真实的，收敛时，生成器样本与真实样本不可区分，判别器处处输出 $\frac12$，然后就可以丢弃判别器。

不幸的是实践中由神经网络表示的 $g$ 及 $d$ 以及 $\max_d v(g,d)$ 不凸时，GAN 中的学习可能是困难的，这是由生成器和判别器的博弈导致的。

GAN 训练过程中一个不寻常的能力是它可以拟合向训练点分配零概率的概率分布。生成器网络学习跟踪其点在某种程度上类似于训练点的流形，而不是最大化特定点的对数概率。

### 7.5 Generative Moment Matching Networks

生成矩匹配网络是另一种基于可微生成器网络的生成模型，特点是不需要与任何其他网络配对。生成矩匹配网络使用矩匹配的技术训练，其基本思想是令模型生成的样本的尽可能多的统计量与训练集中的样本相似。而所谓的矩，是指对随机变量的不同幂次的期望，例如第一矩是均值，第二矩是平方的均值（未归一化的方差），更一般地：
$$
\mathbb E_x\prod_i x_i^{ni}
$$
其中 $n=[n_1,n_2,\dotsb,n_d]^\top$ 是一个非负整数的向量。

我们通过最小化一个被称为最大平均偏差（MMD）的代价函数来训练生成矩匹配网络，该代价函数通过向核函数定义的特征空间隐式映射在无限维空间中测量第一矩的误差，使得对无限维向量的计算变得可行，从而避免了对所有矩的穷举。

来自生成矩匹配网络的样本令人失望，但是可以通过将生成器网络与自编码器网络组合来改进。首先训练自编码器以重构训练集，接下来，自编码器的编码器用于将整个训练集转换到编码空间，然后训练生成器网络以生成编码样本，这些编码样本可以经解码器映射到视觉上里那个人满意的样本。

生产矩匹配网络必须根据许多样本的经验平均值计算矩，因此不可能将训练更新作为一个训练样本或仅来自生成器网络的一个样本的函数。批量太小时，MMD 会低估采样分布的真实变化量，批量太大时，训练过程会减慢。

与 GAN 一样，生成矩匹配网络可以为样本点分配零概率。

### 7.6 Auto-Regressive Networks

自回归网络是没有潜在变量的有向概率模型，这些模型中的条件概率分布由神经网络表示。

最简单的自回归网络的形式是没有隐藏单元，没有参数或特征共享的形式。每个 $P(x_i\mid x_{i-1},\dotsb,x_1)$ 被参数化为线性模型（对于实值数据表示线性回归，对于二值离散数据表示 softmax 回归）。

如果变量是连续的，线性自回归网络只是表示多元高斯分布的另一种方式，只能捕获观察变量之间线性的成对相互作用。线性自回归网络本质上是线性分类方法在生成式建模上的推广。因此，它们具有与线性分类器相同的优缺点。

神经自回归网络具有与逻辑自回归网络相同的从左到右的图模型，但在该图模型中采用不同的条件分布参数，新的参数化更强大，它可以根据需求随意增加容量，并允许近似任意的联合分布。新的参数化还可以引入深度学习中常见的参数共享和特征共享改进泛化能力并避免维度灾难。

![AR](./images/17.7.png)

神经自密度估计器（NADE）相较于原始的神经自回归网络引入了附加的参数共享方案：

![NADE](./images/17.8.png)

另一个非常有趣的神经自回归架构的扩展摆脱了为观察到的变量选择任意顺序的需要，该想法是训练网络以能够通过随机采样顺序来处理任何顺序。这使得人们可以非常高效地使用训练好的自回归网络执行任何推断问题。由于变量的许多顺序是可能的，变量的每个顺序 $o$ 产生不同的 $p(x\mid o)$，我们可以组成许多 $o$ 值模型的集成：
$$
p_{ensemble}(x)=\frac1k\sum_{i=1}^k p(x\mid o^{(i)})
$$

## 8 Drawing Samples from Autoencoders

对于某些类型的自编码器如变分自编码器，它们明确地表示概率分布并且允许直接原始采样，而大多数其他类型的自编码器需要 MCMC 采样。

收缩自编码器被设计为恢复数据流形切面的估计。这意味着使用注入噪声的重复编码和解码将引起沿着流形表面的随机游走 ，这种流形扩散技术是马尔可夫链的一种。

广义去噪自编码器由去噪分布指定，给定损坏输入之后，对干净的估计进行采样，马氏链的每个步骤包括：

- 从先前状态开始注入噪声，从 $C(\widetilde x\mid x)$ 采样 $\widetilde x$
- 将 $\widetilde x$ 编码为 $h=f(\widetilde x)$
- 解码 $h$ 以获得 $p(x\mid \omega=g(h))=p(x\mid \widetilde x)$ 的参数 $\omega=g(h)$
- 从 $p(x\mid \omega=g(h))=p(x\mid \widetilde x)$ 采样下一个状态 $x$

如果 $p(x\mid \widetilde x)$ 对应真实分布的一致估计量，则上述马氏链的平稳分布形成数据生成分布 $x$ 的一致估计量。

与玻尔兹曼机类似，去噪自编码器可以用于从条件分布 $p(x_f\mid x_o)$ 中采样，只需要夹合观察单元 $x_f$ 并在给定 $x_f$ 和采出的潜在变量下对自由单元重新采样。

## 9 Generative Stochastic Networks

生成随机网络（GSN）是去噪自编码器的推广，除可见变量 $x$ 之外，生成马氏链中还包括潜在变量 $h$ 。GSN 由两个条件概率分布参数化，指定马氏链的一步：

-  $p(x^{(k)}\mid h^{(k)})$ 指示在给定当前潜在状态下如何产生下一个可见变量
- $p(h^{(k)}\mid h^{(k-1)},x^{(k-1)})$ 指示在给定先前的潜在状态和可见变量下如何更新潜在状态变量

去噪自编码器和 GSN 不同于经典的概率模型，它们自己参数化生成过程而不是通过可见和潜变量的联合分布的数学形式，如果后者存在则被定义为马氏链的稳态分布。
