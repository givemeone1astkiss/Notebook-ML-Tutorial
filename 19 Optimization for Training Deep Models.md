# Optimization for Training Deep Models

## 1 How Learning Differs from Pure Optimization

用于深度学习训练的优化算法与传统的优化算法的区别是，机器学习通常是间接作用于我们所关注的性能度量 $P$ 的，在学习的过程中，我们只是间接地优化 $P$，希望通过降低代价函数 $J(\theta)$ 来提高 $P$，而纯粹的优化算法直接最小化 $J$ 本身。

童话参观，代价函数可以写作训练集上的期望（平均）的形式：
$$
J(\theta)=\mathbb E_{(x,y)\sim \hat p_{data}}L(f(x;\theta),y)
$$
其中 $L$ 是每个样本的损失函数，$f(x;\theta)$ 是输入 $x$ 时所预测的输出，$\hat p_{data}$ 是经验分布。

通常，我们的目标并不是最小化经验分布上的期望，而是来自数据分布本身的期望：
$$
J^*(\theta)=\mathbb E_{(x,y)\sim p_{data}}L(f(x;\theta),y)
$$

### 1.1 Empirical Risk Minimization (ERM)

机器学习任务中，将 $J^*(\theta)$ 称为风险（risk），最小化风险是机器学习任务的根本目标。然而通常真实的数据分布 $p_{data}$ 对我们是不可见的，一种间接的优化方法是最小化经验风险：
$$
\mathbb E_{x,y\sim \hat p_{data}}[L(f(x;\theta),y)]=\frac1m\sum_{i=1}^mL(f(x^{(i)};\theta),y^{(i)})
$$
其中 $m$ 表示训练样本的数目。基于最小化这种平均训练误差的训练过程被称为经验风险最小化。在此情况下，机器学习仍然和传统的直接优化类似。

然而经验风险最小化很容易造成过拟合因此很多情况下并不可行。最有效的现代优化算法是基于梯度下降的，但是很多有用的损失函数，如 $0-1$ 损失，没有有效的导数。这两个问题说明，在深度学习方法中很少直接使用经验风险最小化作为优化目标。

### 1.2 Surrogate Loss Functions and Early Stopping

有时我们真正关心的损失函数并不能被高效地优化，通常优化代理损失函数作为代替，代理损失函数通常具备一些优点，例如可微、连续等。

某些情况下，使用代理损失函数比原损失函数学到的更多。例如，是应用负对数似然代替阶跃函数作为损失时，在训练集上的 $0-1$ 损失达到 $0$ 之后，在测试集上的 $0-1$ 损失还能持续下降很长时间，这是因为即使 $0-1$ 损失期望是 $0$ 时，我们还能拉开不同类别的距离以改进分类器的鲁棒性，获得一个更强壮的、更值得信赖的分类器，从而相对于简单地最小化训练集上的平均 $0-1$ 损失，它能够从训练数据中抽取更多信息。

一般的优化和我们用于训练算法的优化有一个显著的不同：训练算法通常不会停留在局部极小值点，反之，机器学习通常优化代理损失函数，但是基于提前终止的收敛条件满足时停止，而提前终止使用真实潜在损失函数，如验证集上的 $0-1$ 损失，这导致优化终止时代理函数仍有较大的导数，而纯优化终止时导数较小。

## 1.3 Batch and Minibatch Algorithms

机器学习优化和一般优化算法的另一个区别是，机器学习算法的目标函数通常可以分解为训练样本上的求和。机器学习中的优化算法在计算参数的每一次更新时通常使用整个代价函数中一部分项来估计代价函数的期望值。

最大似然估计问题可以在对数空间分解成各个样本的总和：
$$
\theta_{ML}=\arg\max_{\theta}\sum_{i=1}^m\log p_{model}(x^{(i)},y^{(i)};\theta)
$$
最大化这个总和等价于最大化训练集在经验分布上的期望：
$$
J(\theta)=\mathbb E_{x,y\sim\hat p_{data}}\log p_{model}(x,y;\theta)
$$
优化算法所用到的目标函数 $J$ 中的大多数属性也是训练集上的期望，例如，最常用的属性是梯度：
$$
\nabla_\theta J(\theta)=\mathbb  E_{x,y\sim \hat p_{data}}\nabla_{\theta}\log p_{model}(x,y;\theta)
$$
准确计算这个期望代价极大，因为我们需要首先在每个样本上评估模型，实践中，我们可以从数据集中随机采样少量的样本，然后计算这些样本上的平均值。

采用这种估计方式的另一个动机是，由于 $n$ 个样本均值的方差是 $\sigma/\sqrt{n}$，其中 $\sigma$ 是样本值真实的标准差，分母  $\sqrt n$ 表明使用更多样本估计梯度的方法的回报是低于线性的。

还有一个动机是训练集的冗余，最坏的情况下，训练集中所有的 $m$ 个样本都是彼此相同的拷贝。基于采样的梯度估计可以使用单个样本计算出正确的梯度，而比原来的做法少了 $m$ 倍时间。实践中，我们会发现大量样本对梯度做出的贡献是相似的。

使用整个训练集的优化算法被称为批量或确定性梯度算法，因为它们会在一个大批量中同时处理所有的样本。每次只使用单个样本的优化算法有时被称为随机或者在线算法。大多数深度学习算法介于二者之间，使用一个以上但并非全部的训练样本，传统上这被称为小批量（minibatch）或者小批量随机算法。

这类算法的典型是随机梯度下降，小批量的大小通常由以下几个因素决定：

- 更大的批量会计算更精确的梯度估计，但是回报是小于线性的
- 极小批量通常难以充分利用多核架构。这促使我们使用一些绝对最小批量，低于这个值的小批量不会减少计算时间
- 如果批量处理中的所有样本都可以并行地处理，那么内存消耗和批量大小成正比，对于很多硬件设施，这是批量大小的限制因素
- 在某些硬件上使用特定大小的数组时，运行时间会更少，尤其在使用 GPU 时，通常使用 $2$ 的幂次作为批量大小可以获得更少的运行时间
- 可能是由于小批量在学习过程中加入了噪声，它们会有一些正则化效果。泛化误差通常在批量为 $1$ 时最好，因为梯度估计的高方差，小批量训练需要较小的学习率以保持稳定性。因为降低的学习率和消耗更多的步骤来遍历整个数据集都会产生更多的步骤，所以总的运行时间会非常大。

不同的算法使用不同的方法从小批量中获得不同的信息。有些算法对采样误差比其他算法更加敏感，可能是由于：

- 它们使用了很难在少量样本上精确获得的信息
- 它们以放大采样误差的方式使用信息

仅使用梯度 $g$ 的更新方法相对鲁棒，并且能够使用较小的批量获得成功，使用 Hessian 矩阵的二阶方法通常需要更大的批量。

小批量是随机抽取的这点也很重要。从一组样本中计算出梯度期望的无偏估计要求这些样本是独立的。我们也希望两个连续的梯度估计是互相独立的，因此两个连续的小批量样本也应该是彼此独立的。因此，有必要在抽取之前打乱样本顺序，实践中我们只需要将样本打乱一次，然后按照这个顺序存储起来就够了。之后进行抽取的顺序是固定的，这种偏离真实随机采样的方式并没有大的有害影响。

很多机器学习上的优化方式可以分解为并行地计算呢不同样本上单独的更新，我们在计算小批量 $X$ 上最小化 $J(X)$ 的更新时，同时可以计算其他小批量上的更新。

使用小批量梯度下降的另一个动机是，直到重复使用样本之前，小批量梯度下降都会遵循着真实泛化误差的梯度。很多小批量随机梯度下降方法的实现都会打乱数据顺序依次，然后多次遍历数据来更新参数。第一次遍历时，每个小批量都用来计算真实泛化误差的无偏估计，第二次遍历时，估计将会是有偏的，因为它重新抽取的已经使用过的样本。

在 $x$ 和 $y$ 时离散的时，以上的等价性很容易得到。在这种情况下，泛化误差可以表示为：
$$
J^*(\theta)=\sum_x\sum_yp_{data}(x,y)L(f(x,\theta),y)
$$
上式的准确梯度是：
$$
g=\nabla_\theta J^*(\theta)=J^*(\theta)=\sum_x\sum_yp_{data}(x,y)\nabla_\theta L(f(x,\theta),y)
$$
在变量离散的情况下得到的结果是类似的。因此我们可以从数据生成分布 $p_{data}$ 抽取小批量样本 $\{x^{(1)},\dotsb,x^{(m)}\}$ 以及对应的目标 $y^{(i)}$，然后计算该小批量上损失函数关于 对应参数的梯度：
$$
\hat g=\frac1m\nabla_\theta\sum_iL(f(x^{(i)};\theta),y^{(i)})
$$
因此获得泛化误差准确梯度的无偏估计，最后在泛化误差上使用 SGD 方法在 $\hat g$ 上更新参数。

这个解释只能用于样本没有重复使用的情况，但是对训练数据的额外遍历也会由于减小训练误差而得到足够的好处，以抵消其带来的训练误差和测试误差间差距的增加。

## 2 Challenges in Neural Network Optimization

### 2.1 Ill-Conditioning

Hessian 矩阵的病态是优化凸函数时最常见的问题之一，其体现于随机梯度下降会在某些位置停滞，即使很小的更新步长也会导致代价函数的增加。

代价函数的二阶泰勒展开预测梯度下降中的 $\epsilon g$ 会增加 $\frac12 \epsilon^2 g^\top Hg-\epsilon g^\top g$ 到代价中，当 $\frac12 \epsilon^2 g^\top Hg$ 大于 $\epsilon g^\top g$ 时，梯度的病态会成为问题，在很多情况中，梯度范数不会再训练过程中显著减少，但是 $g^\top Hg$ 的增长会超过一个数量级，其结果是即使在梯度较强的区域，学习也会十分缓慢，因为学习率必须收缩以弥补更强的曲率。

尽管病态还存在于除了神经网络训练的其他情况中，有些适用于其他情况的解决病态的技术并不适用于神经网络。

### 2.2 Local Minima

凸优化的一个特点是其可以简化为寻找一个局部极小点的问题，任何一个局部极小点都是全局极小点。有些凸函数的底部是一个平坦的区域，而不是单一的全局最小点，但该平坦区域中的任意点都是一个可接受的解，优化一个凸问题时，若发现了任何形式的临界点，我们都会知道已经找到了一个不错的可行解。

对于非凸的优化问题例如神经网络来说，可能会存在多个局部极小值，但是这并不是主要的问题。

由于模型可辨识性的问题，神经网络和任意具有多个等效参数化潜变量的模型都会具有多个局部极小值。如果一个足够大的训练集可以唯一确定一组模型参数，那么该模型被称为可辨认的。带有潜变量的模型通常是不可辨认的，因为通过潜变量的交换我们可以得到等价的模型。这种不可辨认行称为权重空间的对称性。

除了权重空间的对称性，还有很多原因导致神经网络是不可辨认的，例如，在任意整流线性网络或者 maxout 网络中，我们可以将传入权重和偏置扩大 $\alpha$ 倍，然后将传出权重扩大 $1/\alpha$ 倍，而保持模型等价。这意味着如果代价函数不包括权重衰减这种直接依赖权重而非模型输出的项，那么整流线性网络或者 maxout 网络的每一个局部极小点都在等价的局部极小值的 $(m\times n)$ 维双曲线上。

由模型可辨识问题带来的多局部极小值都有相同的代价函数值，因此这些局部极小值并不是非凸带来的问题。

如果局部极小值相比全局最小点拥有很大的代价，局部极小值会带来很大的隐患。如果具有很大代价的局部极小值是常见的，那么这将给基于梯度的优化算法带来极大的问题。

对于实际中感兴趣的网络，是否存在大量代价很高的局部极小值，优化算法是否会碰到这些局部极小值，都是尚未解决的公开问题。

### 2.3 Plateaus, Saddle Points and Other Flat Regions

对于很多高维非凸函数而言，局部极小值远少于另一类梯度为零的点——鞍点。鞍点处 Hessian 矩阵同时具有正负特征值，位于正特征值对应的特征向量的方向的点比鞍点具有更大的代价，而位于负特征值对应的特征向量方向的点比鞍点有更大的代价，反之，位于负特征值对应的特征向量方向的点有更小的代价。

在多类随机函数中，鞍点和局部极小值的比率的期望随 $n$ 以指数级增长，而在很多神经网络中情况是类似的。

对于只使用梯度信息的一阶优化算法，优化轨迹可以迅速逃逸出鞍点，但是对于牛顿法而言，鞍点显然是一个问题，因为在梯度下降中，优化过程旨在寻找一条使得代价减小的路径，而不是明确寻找梯度为 $0$ 的点，而牛顿法的目的则是寻求梯度为 $0$ 的点，如果没有适当的修改，牛顿法就会跳进一个鞍点。因此这或许是高维空间中二阶方法无法成功取代一阶方法扩展到大型神经网络的一个原因。

也可能存在恒值的、宽且平坦的区域。在这些区域，梯度和 Hessian 矩阵都是零。这种退化的情形是所有数值优化算法的主要原因。

### 2.4 Cliffs and Exploding Gradients

多层神经网络通常存在向悬崖一样的斜率较大的区域，这是由于几个较大的权重相乘导致的，遭遇梯度较大的悬崖区域时，参数会在一轮内有极大的改变幅度，从而完全跳过悬崖结构。

我们使用梯度截断方式来避免悬崖区域的不良影响，当传统更新方式提议一个极大步长的更新时候，梯度截断会减小步长，使其不太可能走出梯度近似为最陡下降方向的悬崖区域。

### 2.5 Long-Term Dependencies

当计算图变得极深时，神经网络优化算法会面临另一个难题，即长期依赖问题——由于深层的结构使模型丧失了学习到先前信息的能力，优化变得极其困难。

假设某个计算图中包含一条反复与矩阵 $W$ 相乘的路径，那么 $t$ 步之后，相当于乘以 $W^t$，假设 $W$ 有特征值分解 $W=V\mathrm{diag}(\lambda)V^{-1}$，在此情况下，很容易看出：
$$
W^t=(V\mathrm{diag}(\lambda)V^{-1})^t=V\mathrm{diag}(\lambda)^tV^{-1}
$$
这个结构会导致梯度消失（$\lambda_i<1$）与爆炸（$\lambda_i>1$）问题，前者使得我们难以知道参数朝着哪个方向移动能改进代价函数，而梯度爆炸会使得学习不稳定。

此处描述的各时间步重复与 $W$ 相乘非常类似于寻求矩阵 $W$ 的最大特征值及对应特征向量的幂方法。从这个观点来看，$x^\top W^t$ 最终会丢弃 $x$ 中所有与 $W$ 的主特征向量正交的成分。

在前馈神经网络中，我们并不存在这种形式的参数共享，因此即使使用非常深层的前馈神经网络，也能很大程度上避免梯度消失与爆炸的问题，而在循环神经网络中则不然。

### 2.6 Inexact Gradients

大多数情况下我们用于优化的梯度或 Hessian 矩阵都会存在噪声甚至偏差。而在另一些情况下我们希望最小化的目标函数是难解的，在此情况下我们只能对梯度进行近似或者使用代理损失函数。

### 2.7 Poor Correspondence between Local and Global Structure

如果参数更新的方向在局部改进很大，但并没有指向代价低得多的遥远区域，那么我们有可能在单点处克服以上所有困难，但仍然表现不佳。

大多数优化研究的难点集中于训练是否找到了全局最小点、局部极小点或是鞍点，但在实践中神经网络不会到达任何一种临界点，甚至这些临界点不一定存在。

当目标函数有诸如病态条件或不连续梯度的问题，使得梯度为目标函数提供较好近似的区间非常小时，步长为 $\epsilon$ 的局部下降可能定义了到达解的合理的最短路径，但是我们只能计算步长为 $\delta\ll\epsilon$ 的局部下降方向，在这种情况下局部下降或许能定义通向解的路径，但是该路径包含的更新次数过多，计算代价过大。

当目标函数存在一个宽而平的区域时，局部信息不能为全局的优化提供任何指导。

其他情况下，局部移动可能过于贪心，只是单纯朝代价下降的方向移动，却和所有可行解南辕北辙。

许多现有研究方法在求解具有困难全局结构的问题时，旨在寻求良好的初始点， 而不是开发非局部范围更新的算法。

## 3 Basic Algorithms

## 3.1 Stochastic Gradient Descent